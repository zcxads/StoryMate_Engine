import json
import logging
import re
import asyncio
from typing import Dict, Any, List, Tuple, Optional
from langsmith.run_helpers import traceable
from langchain_core.prompts import PromptTemplate

from app.utils.logger.setup import setup_logger
from app.utils.language.generator import language_generator
from app.prompts.language.language_detection.detector import get_language_detection_prompt_config, get_supported_languages
from app.core.config import settings

# ë¡œê±° ì„¤ì •
logger = setup_logger('language_detection', 'logs/language')

@traceable(run_type="chain")
async def detect_language_with_ai(text: str, model_name: str = None) -> Dict[str, any]:
    """
    AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.

    Args:
        text: ì–¸ì–´ë¥¼ ê°ì§€í•  í…ìŠ¤íŠ¸
        model_name: ì‚¬ìš©í•  AI ëª¨ë¸ (ê¸°ë³¸ê°’: ì¤‘ì•™ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)

    Returns:
        Dict containing:
        - primary_language: ì£¼ìš” ì–¸ì–´ ì½”ë“œ
        - confidence: ì‹ ë¢°ë„ (0.0-1.0)
        - detected_languages: ê°ì§€ëœ ëª¨ë“  ì–¸ì–´ ëª©ë¡
        - is_mixed: í˜¼í•© ì–¸ì–´ ì—¬ë¶€
    """
    try:
        # ëª¨ë¸ì´ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì¤‘ì•™ ì„¤ì • ì‚¬ìš©
        if not model_name:
            model_name = settings.default_llm_model

        logger.info(f"Starting AI language detection for text: '{text[:50]}...' using {model_name}")

        # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš°
        if not text or len(text.strip()) <= 1:
            logger.warning("Text is empty or too short for language detection")
            return {
                "primary_language": "unknown",
                "confidence": 0.0,
                "detected_languages": [],
                "is_mixed": False,
                "error": "Text too short"
            }

        # í…ìŠ¤íŠ¸ ìƒ˜í”Œë§ (500ì ì´ˆê³¼ ì‹œ 20%ë§Œ ì‚¬ìš©)
        original_length = len(text)
        if original_length > 500:
            sample_size = int(original_length * 0.2)
            # ì•ìª½ 10% + ì¤‘ê°„ 10% ì¶”ì¶œ
            first_half_size = sample_size // 2
            second_half_size = sample_size - first_half_size

            front_sample = text[:first_half_size]
            middle_start = (original_length - second_half_size) // 2
            middle_sample = text[middle_start:middle_start + second_half_size]

            sampled_text = front_sample + " ... " + middle_sample
            logger.info(f"Text sampling ê²°ê³¼: {sampled_text}")
            text = sampled_text

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_config = get_language_detection_prompt_config()
        prompt = PromptTemplate(
            template=prompt_config["template"]
        )

        # AI ëª¨ë¸ í˜¸ì¶œ
        chain = prompt | language_generator
        response = await chain.ainvoke(
            {"text": text},
            config={"model": model_name}
        )
        
        # ì‘ë‹µ íŒŒì‹±
        result = parse_language_detection_response(response.content.strip())
        
        logger.info(f"AI Language detection completed: {result['primary_language']} (confidence: {result['confidence']})")
        return result
        
    except Exception as e:
        logger.error(f"Error in AI language detection: {str(e)}", exc_info=True)
        return result

def parse_language_detection_response(response: str) -> Dict[str, any]:
    """
    AI ëª¨ë¸ì˜ ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²°ê³¼ë¡œ ë³€í™˜
    
    Expected response format:
    PRIMARY: ko
    CONFIDENCE: 0.95
    DETECTED: ko, en
    MIXED: false
    """
    try:
        lines = response.strip().split('\n')
        result = {
            "primary_language": "unknown",
            "confidence": 0.0,
            "detected_languages": [],
            "is_mixed": False
        }
        
        supported_languages = get_supported_languages()
        
        for line in lines:
            line = line.strip()
            if line.startswith("PRIMARY:"):
                result["primary_language"] = line.split(":", 1)[1].strip()
            elif line.startswith("CONFIDENCE:"):
                try:
                    result["confidence"] = float(line.split(":", 1)[1].strip())
                except ValueError:
                    result["confidence"] = 0.0
            elif line.startswith("DETECTED:"):
                languages_str = line.split(":", 1)[1].strip()
                result["detected_languages"] = [lang.strip() for lang in languages_str.split(",") if lang.strip()]
            elif line.startswith("MIXED:"):
                mixed_str = line.split(":", 1)[1].strip().lower()
                result["is_mixed"] = mixed_str in ["true", "yes", "1"]
        
        # ê²€ì¦
        if result["primary_language"] not in supported_languages and result["primary_language"] != "unknown":
            logger.warning(f"Unknown primary language detected: {result['primary_language']}")
            result["primary_language"] = "unknown"
        
        # detected_languagesê°€ ë¹„ì–´ìˆìœ¼ë©´ primary_languageë¡œ ì±„ì›€
        if not result["detected_languages"] and result["primary_language"] != "unknown":
            result["detected_languages"] = [result["primary_language"]]
        
        return result
        
    except Exception as e:
        logger.error(f"Error parsing AI response: {str(e)}")
        return {
            "primary_language": "unknown",
            "confidence": 0.0,
            "detected_languages": [],
            "is_mixed": False,
            "error": f"Parsing failed: {str(e)}"
        }

async def is_translation_needed_ai(text: str, target_language: str, model_name: str = None) -> bool:
    """
    AI ê¸°ë°˜ ì–¸ì–´ ê°ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ì´ í•„ìš”í•œì§€ íŒë‹¨

    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        target_language: ëŒ€ìƒ ì–¸ì–´
        model_name: ì‚¬ìš©í•  AI ëª¨ë¸ (ê¸°ë³¸ê°’: ì¤‘ì•™ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)

    Returns:
        bool: ë²ˆì—­ì´ í•„ìš”í•˜ë©´ True, ì•„ë‹ˆë©´ False
    """
    try:
        # ëª¨ë¸ì´ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì¤‘ì•™ ì„¤ì • ì‚¬ìš©
        if not model_name:
            model_name = settings.default_llm_model

        # AI ì–¸ì–´ ê°ì§€ ìˆ˜í–‰
        detection_result = await detect_language_with_ai(text, model_name)
        
        if detection_result.get("error"):
            logger.warning(f"AI detection failed: {detection_result.get('error')}")
        
        primary_language = detection_result["primary_language"]
        confidence = detection_result["confidence"]
        detected_languages = detection_result["detected_languages"]
        is_mixed = detection_result["is_mixed"]
        
        logger.info(f"ğŸ” AI Detection: primary={primary_language}, confidence={confidence:.2f}, detected={detected_languages}, mixed={is_mixed}")
        
        # ê°ì§€ ì‹¤íŒ¨í•œ ê²½ìš°
        if primary_language == "unknown":
            logger.info("ğŸ” AI Detection: Low confidence or unknown language -> default to translation needed")
            return True
        
        # ì´ë¯¸ ëŒ€ìƒ ì–¸ì–´ì¸ ê²½ìš°
        if primary_language == target_language:
            if confidence >= 0.8:
                logger.info(f"ğŸ” AI Detection: High confidence match with target language -> no translation needed")
                return False
            else:
                logger.info(f"ğŸ” AI Detection: Low confidence match -> translation recommended")
                return True
        
        # ë‹¤ë¥¸ ì–¸ì–´ì¸ ê²½ìš°
        logger.info(f"ğŸ” AI Detection: Different language detected ({primary_language} -> {target_language}) -> translation needed")
        return True
        
    except Exception as e:
        logger.error(f"Error in AI-based translation decision: {str(e)}", exc_info=True)
        # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ ë²ˆì—­ í•„ìš”ë¡œ íŒë‹¨
        return True
